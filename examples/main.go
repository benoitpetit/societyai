// Script d'exemples pour SocietyAI
//
// Ce script permet de tester les diff√©rents modes de SocietyAI:
// - Mode standard (basic): juxtaposition de perspectives vari√©es
// - Mode avec synth√®se (with_synthesis): synth√®se des perspectives par un mod√®le d√©di√©
// - Mode collaboratif (collaborative): r√©flexion profonde et int√©gr√©e en 4 √©tapes
//
// L'utilisateur peut choisir le mode √† utiliser via un menu interactif.

package main

import (
	"bufio"
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"os"
	"strings"
	"time"

	"github.com/benoitpetit/societyai"
)

// GeminiModel impl√©mente l'interface societyai.AIModel
type GeminiModel struct {
	ModelName    string
	APIKey       string
	BaseURL      string
	HttpClient   *http.Client
	Conversation []Message
	MaxRetries   int
	RetryDelay   time.Duration
}

// Message repr√©sente un message dans la conversation
type Message struct {
	Role    string `json:"role"`
	Content string `json:"content"`
}

// Part repr√©sente une partie d'un contenu dans l'API Gemini
type Part struct {
	Text string `json:"text"`
}

// Content repr√©sente un contenu dans l'API Gemini
type Content struct {
	Role  string `json:"role,omitempty"`
	Parts []Part `json:"parts"`
}

// NewGeminiModel cr√©e un nouveau mod√®le Gemini
func NewGeminiModel(modelName, apiKey string) *GeminiModel {
	return &GeminiModel{
		ModelName:    modelName,
		APIKey:       apiKey,
		BaseURL:      "https://generativelanguage.googleapis.com/v1beta/models",
		HttpClient:   &http.Client{Timeout: 120 * time.Second},
		Conversation: []Message{},
		MaxRetries:   3,
		RetryDelay:   2 * time.Second,
	}
}

// Name retourne le nom du mod√®le (impl√©mente l'interface AIModel)
func (m *GeminiModel) Name() string {
	return m.ModelName
}

// Process envoie une requ√™te √† l'API Gemini et retourne la r√©ponse (impl√©mente l'interface AIModel)
func (m *GeminiModel) Process(ctx context.Context, prompt string) (string, error) {
	// Ajouter le message utilisateur √† la conversation
	m.Conversation = append(m.Conversation, Message{
		Role:    "user",
		Content: prompt,
	})

	// Convertir la conversation au format attendu par Gemini
	contents := []Content{}

	// Ajouter l'historique des messages
	for _, msg := range m.Conversation {
		content := Content{
			Role: msg.Role,
			Parts: []Part{
				{Text: msg.Content},
			},
		}
		contents = append(contents, content)
	}

	// Pr√©parer le corps de la requ√™te
	requestBody := struct {
		Contents         []Content `json:"contents"`
		GenerationConfig struct {
			MaxOutputTokens int     `json:"maxOutputTokens,omitempty"`
			Temperature     float64 `json:"temperature,omitempty"`
		} `json:"generationConfig,omitempty"`
	}{
		Contents: contents,
		GenerationConfig: struct {
			MaxOutputTokens int     `json:"maxOutputTokens,omitempty"`
			Temperature     float64 `json:"temperature,omitempty"`
		}{
			MaxOutputTokens: 2048,
			Temperature:     0.7,
		},
	}

	jsonData, err := json.Marshal(requestBody)
	if err != nil {
		return "", err
	}

	var lastError error
	// Impl√©menter un m√©canisme de retry
	for attempt := 0; attempt <= m.MaxRetries; attempt++ {
		if attempt > 0 {
			fmt.Printf("‚ö†Ô∏è Tentative %d/%d apr√®s erreur: %v\n", attempt, m.MaxRetries, lastError)
			time.Sleep(m.RetryDelay * time.Duration(attempt)) // D√©lai exponentiel
		}

		// Construire l'URL compl√®te avec la cl√© API
		fullURL := fmt.Sprintf("%s/%s:generateContent?key=%s", m.BaseURL, m.ModelName, m.APIKey)

		// Cr√©er et envoyer la requ√™te HTTP
		req, err := http.NewRequestWithContext(
			ctx,
			"POST",
			fullURL,
			bytes.NewBuffer(jsonData),
		)
		if err != nil {
			lastError = err
			continue
		}

		req.Header.Add("Content-Type", "application/json")

		resp, err := m.HttpClient.Do(req)
		if err != nil {
			lastError = err
			continue
		}
		defer resp.Body.Close()

		if resp.StatusCode != http.StatusOK {
			body, _ := io.ReadAll(resp.Body)
			lastError = fmt.Errorf("erreur API: %s - %s", resp.Status, string(body))
			continue
		}

		// D√©coder la r√©ponse
		var result struct {
			Candidates []struct {
				Content struct {
					Parts []struct {
						Text string `json:"text"`
					} `json:"parts"`
					Role string `json:"role"`
				} `json:"content"`
				FinishReason string `json:"finishReason"`
			} `json:"candidates"`
			PromptFeedback struct {
				BlockReason string `json:"blockReason,omitempty"`
			} `json:"promptFeedback"`
		}

		err = json.NewDecoder(resp.Body).Decode(&result)
		if err != nil {
			lastError = err
			continue
		}

		if len(result.Candidates) == 0 {
			lastError = fmt.Errorf("r√©ponse vide re√ßue de l'API")
			continue
		}

		// V√©rifier si la requ√™te a √©t√© bloqu√©e pour des raisons de s√©curit√©
		if result.PromptFeedback.BlockReason != "" {
			lastError = fmt.Errorf("requ√™te bloqu√©e: %s", result.PromptFeedback.BlockReason)
			continue
		}

		// Obtenir la r√©ponse textuelle
		responseText := ""
		for _, part := range result.Candidates[0].Content.Parts {
			responseText += part.Text
		}

		// Ajouter la r√©ponse √† la conversation
		m.Conversation = append(m.Conversation, Message{
			Role:    "model",
			Content: responseText,
		})

		return responseText, nil
	}

	return "", fmt.Errorf("√©chec apr√®s %d tentatives: %v", m.MaxRetries, lastError)
}

func main() {
	// R√©cup√©rer la cl√© API depuis une variable d'environnement
	apiKey := os.Getenv("GEMINI_API_KEY")
	if apiKey == "" {
		fmt.Println("‚ö†Ô∏è  Veuillez d√©finir la variable d'environnement GEMINI_API_KEY")
		fmt.Println("    Exemple: export GEMINI_API_KEY=votre_cl√©_api_gemini_ici")
		os.Exit(1)
	}

	fmt.Println("üß† SocietyAI - Exemples unifi√©s")
	fmt.Println("==============================")
	fmt.Println()
	fmt.Println("Choisissez le mode que vous souhaitez tester :")
	fmt.Println("1. Mode standard (juxtaposition de perspectives)")
	fmt.Println("2. Mode avec synth√®se (synth√®se des perspectives par un mod√®le d√©di√©)")
	fmt.Println("3. Mode collaboratif (r√©flexion profonde et int√©gr√©e en 4 √©tapes)")
	fmt.Println()

	// Lire le choix de l'utilisateur
	scanner := bufio.NewScanner(os.Stdin)
	fmt.Print("Votre choix (1-3) : ")
	var choice string
	if scanner.Scan() {
		choice = strings.TrimSpace(scanner.Text())
	}

	// Nombre d'agents (par d√©faut : 4)
	agentCount := 4
	fmt.Printf("Nombre d'agents: %d\n", agentCount)

	// Utiliser le mod√®le gemini-2.0-flash par d√©faut
	modelName := "gemini-2.0-flash"
	fmt.Printf("Mod√®le utilis√©: %s\n", modelName)

	// Inviter l'utilisateur √† saisir le prompt
	fmt.Println("\nüîç Entrez votre prompt (ou appuyez sur Entr√©e pour utiliser l'exemple) :")
	var prompt string
	if scanner.Scan() {
		prompt = strings.TrimSpace(scanner.Text())
	}
	if prompt == "" {
		prompt = "Comment cr√©er une API RESTful simple en Golang?"
		fmt.Printf("   Utilisation du prompt par d√©faut: \"%s\"\n", prompt)
	}

	// Cr√©er les mod√®les IA
	models := make([]societyai.AIModel, agentCount)
	for i := 0; i < agentCount; i++ {
		models[i] = NewGeminiModel(modelName, apiKey)
	}

	// Mesurer le temps d'ex√©cution
	startTime := time.Now()

	// Variable pour stocker le r√©sultat
	var result string
	var err error

	// Ex√©cuter le mode choisi
	switch choice {
	case "1":
		// Mode standard
		fmt.Println("\nüöÄ D√©marrage du mode standard...")
		fmt.Println("   Les agents vont analyser le prompt avec des perspectives diff√©rentes")

		result, err = societyai.Society(prompt, agentCount, models, true)

	case "2":
		// Mode avec synth√®se
		fmt.Println("\nüöÄ D√©marrage du mode avec synth√®se...")
		fmt.Println("   Les agents vont analyser le prompt puis un mod√®le d√©di√© synth√©tisera leurs perspectives")

		// Cr√©er un mod√®le sp√©cifique pour la synth√®se
		synthesisModel := NewGeminiModel(modelName, apiKey)

		result, err = societyai.SocietyWithSynthesis(prompt, agentCount, models, true, synthesisModel)

	case "3":
		// Mode collaboratif
		fmt.Println("\nüöÄ D√©marrage du mode collaboratif...")
		fmt.Println("   Processus en 4 √©tapes :")
		fmt.Println("   1. Analyse initiale de la demande")
		fmt.Println("   2. Exploration de dimensions compl√©mentaires")
		fmt.Println("   3. Int√©gration des analyses")
		fmt.Println("   4. G√©n√©ration de la r√©ponse finale")

		result, err = societyai.SocietyCollaborative(prompt, agentCount, models, true)

	default:
		fmt.Println("‚ùå Choix invalide. Veuillez choisir 1, 2 ou 3.")
		os.Exit(1)
	}

	if err != nil {
		fmt.Printf("‚ùå Erreur: %v\n", err)
		os.Exit(1)
	}

	// Calculer le temps d'ex√©cution
	duration := time.Since(startTime)

	// Afficher le r√©sultat
	fmt.Println("\nüìä R√©ponse finale :")
	fmt.Println("----------------------------------------")
	fmt.Println(result)
	fmt.Println("----------------------------------------")
	fmt.Printf("\n‚è±Ô∏è Temps d'ex√©cution: %s\n", duration)
}
